# -*- coding: utf-8 -*-
"""nyt.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oEHZPsB21QbQEEVP0h3Fw1_MZessiJlD

##TF-IDF on NYTimes articles 

Task: Use singular value decomposition (SVD) on a subset of NYTimes articles. Use bag of words representation in which documents are represented by the counts of words, excluding common stop words.
"""

import pickle as pkl
import numpy as np
import gzip
from numpy import linalg as LA
import matplotlib.pyplot as plt

filename = '/content/nyt.pkl.gz'
with gzip.open(filename, 'rb') as fh:
  nyt = pkl.load(fh)
documents = nyt['docs']
vocab = nyt['vocab']

# Create reverse lookup table.
vocab_indices = dict([(w, i) for (i, w) in enumerate(vocab)])

M = len(documents)
N = len(vocab)
print('%d documents, %d words' % (M,N))

count_mat = np.zeros((M,N))
for mm, doc in enumerate(documents):
  for word, count in doc.items():
    count_mat[mm, vocab_indices[word]] = count

#transform count_mat into a term frequency matrix 
#tf = count of words in document / total number of words in document
tf = count_mat / np.sum(count_mat, axis = 1)[:, np.newaxis]

#compute the idf vector from count_mat
#log(total number of documents/(1 + documents with word n))
idf = np.log(N/(1 + np.sum(count_mat > 0, axis = 0)))

#TF-IDF = TF * IDF element wise multiplication 
tfidf = np.multiply(tf, idf)

#compute the SVD
u, s, vh = np.linalg.svd(tfidf)

#plot the cumulative sum in decreasing values 
plt.xlabel('Singular Values')
plt.ylabel('Cumulative Sum')
plt.title('Cumulative Sum of Singular Values')
plt.plot(np.cumsum(s))
plt.show()

#find top 20 right singular vectors 

for ii in range(20):
  indices = np.argsort(vh[ii,:])[:10]
  print('Topic %d: ' % (ii+1))
  print('\t%s' % (' '.join(vocab[indices])))